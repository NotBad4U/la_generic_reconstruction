\section{Evaluation}
\label{sec:evaluation}

\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline                                                             % Succ - Err -Timeout   % Succ - Error        % Succ - Err - Timeout % Succ - Err - Timeout
\textbf{Logic}                & \textbf{Bench}  & \textbf{Samples} & \textbf{Proofs}       & \textbf{Elaborate} & \textbf{Translate} & \textbf{Check} \\ \hline
\multirow{4}{*}{\tt{LIA}}     & tptp            & 36               &  36 - 0 - 0           &  36 - 0             & 36 - 0 - 0          & 28 - 8 - 0       \\ \cline{2-7} 
                              & Ultimate        & 153              &  120 - 0 - 33         &  73 - 80            & 68 - 5 - 0          & 50 - 18 - 0      \\ \cline{2-7} 
                              & Svcomp'19      & 27               &  27 - 0 - 0           &  25 - 2             & 0 - 25 - 0          & 0                \\ \cline{2-7} 
                              & psyco           & 50               &  48 - 0 - 2           &  48 - 2             & 43 - 0 - 5          & 0 - 39 - 6       \\ \hline
\multirow{2}{*}{\tt{QFLIA}}   & SMPT            & 1568             &  1501 - 67 - 0        &  1491 - 32          & 1470 - 0 - 21       & 804 - 638 - 34   \\ \cline{2-7}
                              & rings           & 294              &  63 - 0 - 231         &  49 - 21            & 49 - 0 - 0          & 7 - 0 - 42       \\ \cline{2-7} 
                              & CAV\_2009       & 85               &  85 - 0 - 0           &  19 - 0             & 19 - 0 - 0          & 19 - 0 - 0       \\ \hline
\multirow{2}{*}{\tt{UFLIA}}   & sledgeh    & 1521             &  1343 - 0 - 178       &  1278 - 222         & 1258 - 13 - 7       & 713 - 467 - 80   \\ \cline{2-7} 
                              & tokeneer        & 1732             &  1732 - 0 - 0         & 1689 - 43           & 1689 - 0 - 0        & 1482 - 197 - 10  \\ \hline
\end{tabular}
\caption{Benchmark samples.}
\label{table:benchmarks-description}
\end{table}

Our benchmark suite, \cref{table:benchmarks-description} is composed of files from the SMT-LIB benchmarks\footnote{\url{https://smtlib.cs.uiowa.edu/benchmarks.shtml}}.
The suite includes a total of 5,466 samples drawn from 9 benchmarks spanning 3 SMT-LIB logics: \texttt{LIA}, \texttt{QFLIA}, and \texttt{UFLIA} that correspond to those covered by our method.
%These were selected because our previous work supported the \texttt{QF} and \texttt{UF} fragments.
Within the logics \texttt{QFLIA} and \texttt{UFLIA}, we prioritized benchmarks with the most significant number of available samples.
Table~\ref{table:benchmarks-description} provides a detailed breakdown of the benchmarks and corresponding results.
The \emph{Logic} column indicates the SMT theory used, while the \emph{Bench} column lists abbreviated benchmark names for conciseness.
The column \emph{Samples} describes the number of problems available with status \emph{unsat}. 
Each of the columns \emph{Proofs}, \emph{Translate}, and \emph{Check} reports a triple in the format \tt{success - error - timeout}, representing respectively the number of successful executions, failed attempts, and timeouts. 
The \emph{Proofs} column reports the number of proofs generated by cvc5\footnote{cvc5 version 1.2.1-dev.144.38fcc340e5 [git 38fcc340e5 on branch main]} that do not contain \lstinline[language=SMT,basicstyle=\ttfamily\footnotesize]|Real| or \lstinline[language=SMT,basicstyle=\ttfamily\footnotesize]|to_real| cast operator.
The \emph{Elaborate} column shows a pair of values: the number of proofs that were successfully elaborated by Carcara, and the number that failed. Only proofs successfully elaborated by Carcara are considered for translation.
The \emph{Translate} column gives the number of proof traces successfully translated into Lambdapi proofs, while the \emph{Check} column indicates the number of these translated proofs that were successfully type-checked by Lambdapi. 

We enforced a timeout of 30 seconds for cvc5 to find a proof and 30 seconds for the translation step with Carcara.
No timeout was imposed during the elaboration step, as the runtime is negligible.
A timeout of 20 seconds was set for Lambdapi when type-checking the final proofs to ensure that proof verification remains as fast as possible.\footnote{All benchmarks were executed in parallel using GNU parallel \cite{tange_2025_15071920} with an Apple silicon M2.} % Ask by the tool to be cited

All nine benchmarks demonstrated consistently reliable proof generation, with few or no timeouts, except for the \emph{rings} benchmark.
The elaboration phase was generally robust, except in the \emph{Ultimate} benchmark, where an error in the elaborator caused failures.
For \texttt{LIA}, performance in the translation and checking stages was mixed. In particular, for \emph{Svcomp'19} and \emph{psyco}, no or few proofs could be translated or verified, mainly due to unsupported simplification rules involving the \texttt{ite} operator.
The \texttt{QFLIA} benchmarks exhibited more reliable proof checking in \emph{SMPT} and \emph{CAV\_2009}, while only a small number of proofs from the \emph{rings} benchmark were successfully checked.
The errors encountered during the elaboration of the \emph{CAV\_2009} come from a bug in the elaborator. Since the samples in this benchmark are derived from a common base problem and increase incrementally in size, the bug propagated across all samples that depend on the same base instance.
This limitation is due to the presence of \texttt{la\_generic} terms with hundreds of uninterpreted variables; the current normalization mechanism, described in \cref{ssec:normalization}, relies on a built-in term ordering that is not sufficiently efficient in this setting.
Benchmarks under \texttt{UFLIA} performed better throughout the pipeline. Most proofs were successfully generated and elaborated, and a large portion were translated and verified by Lambdapi, particularly in the \emph{tokeneer} dataset.
The higher number of errors in \emph{SMPT} and \emph{sledgeh} is primarily due to unsupported RARE rule related to \tt{QF} and \tt{UF} logic, as well as unhandled cases in the \texttt{evaluate} rule for \texttt{LIA}, \texttt{QF}, and \texttt{UF}.

\begin{table}[]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Bench}      & \textbf{Min} & \textbf{Q1} & \textbf{Mean} & \textbf{Q3} & \textbf{Max} \\ \hline
tptp                & 240          & 262         & 263           & 267         & 336          \\ \hline
Ultimate            & 82           & 96          & 100           & 111         & 346          \\ \hline
SMPT                & 52           & 55          & 55            & 56          & 293          \\ \hline
rings               & 670          & 704         & 773           & 826         & 1197         \\ \hline
CAV\_2009           & 54           & 296         & 403           & 498         & 683          \\ \hline
sledgeh             & 53           & 166         & 354           & 552         & 1594         \\ \hline
tokeneer            & 55           & 60          & 61            & 248         & 753          \\ \hline
\end{tabular}
\caption{Lambdapi checking times in milliseconds.}
\label{table:benchmarks-list}
\end{table}

Table~\ref{table:benchmarks-list} reports the Lambdapi proof-checking times in milliseconds, presenting the minimum, first quartile (Q1), mean, third quartile (Q3), and maximum durations for each benchmark.
In most cases, the checking time remains below one second.
% , with the exception of a few outliers particularly in the \emph{sledgehammer} and \emph{rings} benchmarks that exhibit higher upper tails.
